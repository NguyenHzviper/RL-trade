{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import argparse\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alpaca_trade_api as alpaca\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import requests\n",
    "import yfinance as yf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_point = 'https://paper-api.alpaca.markets'\n",
    "api_key = 'PKIQ2QKAFZ51W05KKKD3'\n",
    "api_secret='0fMdgavxKPkHaYR0l8sJ2gKc3eiHHXKDUMbuYGsT'\n",
    "\n",
    "# Symbols for the cryptocurrencies we'd like to buy.\n",
    "btc = \"BTCUSD\"\n",
    "eth = \"ETHUSD\"\n",
    "\n",
    "api = alpaca.REST(api_key, api_secret, end_point, api_version='v2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balance():\n",
    "    account = api.get_account()\n",
    "    return float(account.buying_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will calculate the number of units one can afford given cash to spend and latest price, and round it down according to order of the precision factor.\n",
    "def calculate_order_size(cash_to_spend, latest_price):\n",
    " precision_factor = 10000\n",
    " units_to_buy = float(cash_to_spend * precision_factor / latest_price)\n",
    " units_to_buy /= precision_factor\n",
    " return units_to_buy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buy(symbol, qty):\n",
    "    api.submit_order(symbol=symbol, qty=qty,side='buy', type='market', time_in_force='gtc')\n",
    "\n",
    "def sell(symbol, qty):\n",
    "    api.submit_order(symbol=symbol, qty=qty,side='sell', type='market', time_in_force='gtc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_price(symbol):\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    data = ticker.history(period=\"1d\")  # Fetch daily data\n",
    "    data = data[~data.index.duplicated(keep='last')]  # Remove any duplicate indices\n",
    "    data = data.dropna(subset=['Close'])  # Drop rows with missing 'Close' values\n",
    "    market_price = data['Close'].iloc[-1]\n",
    "    return float(market_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use AAPL (Apple), MSI (Motorola), SBUX (Starbucks)\n",
    "def get_data():\n",
    "  # returns a T x 3 list of stock prices\n",
    "  # each row is a different stock\n",
    "  # 0 = AAPL\n",
    "  # 1 = MSI\n",
    "  # 2 = SBUX\n",
    "  df = pd.read_csv('aapl_msi_sbux.csv')\n",
    "  return df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_make_dir(directory):\n",
    "  if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaler(env):\n",
    "  # return scikit-learn scaler object to scale the states\n",
    "  # Note: you could also populate the replay buffer here\n",
    "\n",
    "  states = []\n",
    "  for _ in range(env.n_step):\n",
    "    action = np.random.choice(env.action_space)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    states.append(state)\n",
    "    if done:\n",
    "      break\n",
    "\n",
    "  scaler = StandardScaler()\n",
    "  scaler.fit(states)\n",
    "  return scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_episode(agent, env, is_train):\n",
    "  # note: after transforming states are already 1xD\n",
    "  state = env.reset()\n",
    "  state = scaler.transform([state])\n",
    "  done = False\n",
    "\n",
    "  while not done:\n",
    "    action = agent.act(state)\n",
    "    next_state, reward, done, info = env.step(action)\n",
    "    next_state = scaler.transform([next_state])\n",
    "    if is_train == 'train':\n",
    "      agent.update_replay_memory(state, action, reward, next_state, done)\n",
    "      agent.replay(batch_size)\n",
    "    state = next_state\n",
    "\n",
    "  return info['cur_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(input_dim, n_action, n_hidden_layers=1, hidden_dim=32):\n",
    "  \"\"\" A multi-layer perceptron \"\"\"\n",
    "\n",
    "  # input layer\n",
    "  i = Input(shape=(input_dim,))\n",
    "  x = i\n",
    "\n",
    "  # hidden layers\n",
    "  for _ in range(n_hidden_layers):\n",
    "    x = Dense(hidden_dim, activation='relu')(x)\n",
    "\n",
    "  # final layer\n",
    "  x = Dense(n_action)(x)\n",
    "\n",
    "  # make the model\n",
    "  model = Model(i, x)\n",
    "\n",
    "  model.compile(loss='mse', optimizer='adam')\n",
    "  print((model.summary()))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The experience replay memory ###\n",
    "class ReplayBuffer:\n",
    "  def __init__(self, obs_dim, act_dim, size):\n",
    "    self.obs1_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "    self.obs2_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "    self.acts_buf = np.zeros(size, dtype=np.uint8)\n",
    "    self.rews_buf = np.zeros(size, dtype=np.float32)\n",
    "    self.done_buf = np.zeros(size, dtype=np.uint8)\n",
    "    self.ptr, self.size, self.max_size = 0, 0, size\n",
    "\n",
    "  def store(self, obs, act, rew, next_obs, done):\n",
    "    self.obs1_buf[self.ptr] = obs\n",
    "    self.obs2_buf[self.ptr] = next_obs\n",
    "    self.acts_buf[self.ptr] = act\n",
    "    self.rews_buf[self.ptr] = rew\n",
    "    self.done_buf[self.ptr] = done\n",
    "    self.ptr = (self.ptr+1) % self.max_size\n",
    "    self.size = min(self.size+1, self.max_size)\n",
    "\n",
    "  def sample_batch(self, batch_size=32):\n",
    "    idxs = np.random.randint(0, self.size, size=batch_size)\n",
    "    return dict(s=self.obs1_buf[idxs],\n",
    "                s2=self.obs2_buf[idxs],\n",
    "                a=self.acts_buf[idxs],\n",
    "                r=self.rews_buf[idxs],\n",
    "                d=self.done_buf[idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVM for agent trading on alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvnAlpaca:\n",
    "    \"\"\"\n",
    "    A 3-stock trading environment.\n",
    "    State: vector of size 7 (n_stock * 2 + 1)\n",
    "        - # shares of stock 1 owned\n",
    "        - # shares of stock 2 owned\n",
    "        - # shares of stock 3 owned\n",
    "        - price of stock 1 (using daily close price)\n",
    "        - price of stock 2\n",
    "        - price of stock 3\n",
    "        - cash owned (can be used to purchase more stocks)\n",
    "    Action: categorical variable with 27 (3^3) possibilities\n",
    "        - for each stock, you can:\n",
    "        - 0 = sell\n",
    "        - 1 = hold\n",
    "        - 2 = buy\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, symbols, initial_investment=20000):\n",
    "        # data\n",
    "        self.symbols = symbols\n",
    "        self.n_stock = len(symbols)\n",
    "        self.n_step = 25\n",
    "        # instance attributes\n",
    "        self.initial_investment = initial_investment\n",
    "        self.cur_step = None\n",
    "        self.stock_owned = None\n",
    "        self.stock_price = None\n",
    "        self.cash_in_hand = None\n",
    "\n",
    "        self.action_space = np.arange(3**self.n_stock)\n",
    "\n",
    "        # action permutations\n",
    "        # returns a nested list with elements like:\n",
    "        # [0,0,0]\n",
    "        # [0,0,1]\n",
    "        # [0,0,2]\n",
    "        # [0,1,0]\n",
    "        # [0,1,1]\n",
    "        # etc.\n",
    "        # 0 = sell\n",
    "        # 1 = hold\n",
    "        # 2 = buy\n",
    "        self.action_list = list(map(list, itertools.product([0, 1, 2], repeat=self.n_stock)))\n",
    "\n",
    "        # calculate size of state\n",
    "        self.state_dim = self.n_stock * 2 + 1\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.cur_step = 0\n",
    "        self.stock_owned = np.zeros(self.n_stock)\n",
    "        self.stock_price = self._get_stock_prices()\n",
    "        self.cash_in_hand = get_balance()\n",
    "        return self._get_obs()\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        assert action in self.action_space\n",
    "\n",
    "        # get current value before performing the action\n",
    "        prev_val = self._get_val()\n",
    "\n",
    "        # update price, i.e. go to the next day\n",
    "        self.cur_step += 1\n",
    "        self.stock_price = self._get_stock_prices()\n",
    "\n",
    "        # perform the trade\n",
    "        self._trade(action)\n",
    "\n",
    "        # get the new value after taking the action\n",
    "        cur_val = self._get_val()\n",
    "\n",
    "        # reward is the increase in portfolio value\n",
    "        reward = cur_val - prev_val\n",
    "\n",
    "        # done if we have run out of data\n",
    "        done = self.cur_step == self.n_step - 1\n",
    "\n",
    "        # store the current value of the portfolio here\n",
    "        info = {'cur_val': cur_val}\n",
    "\n",
    "        # conform to the Gym API\n",
    "        return self._get_obs(), reward, done, info\n",
    "\n",
    "\n",
    "    def _get_obs(self):\n",
    "        obs = np.empty(self.state_dim)\n",
    "        obs[:self.n_stock] = self.stock_owned\n",
    "        obs[self.n_stock:2*self.n_stock] = self.stock_price\n",
    "        obs[-1] = self.cash_in_hand\n",
    "        return obs\n",
    "\n",
    "\n",
    "    def _get_val(self):\n",
    "        return self.stock_owned.dot(self.stock_price) + self.cash_in_hand\n",
    "\n",
    "\n",
    "    def _trade(self, action):\n",
    "        action_vec = self.action_list[action]\n",
    "\n",
    "        sell_index = []\n",
    "        buy_index = []\n",
    "        for i, a in enumerate(action_vec):\n",
    "            if a == 0:\n",
    "                sell_index.append(i)\n",
    "            elif a == 2:\n",
    "                buy_index.append(i)\n",
    "\n",
    "        if sell_index:\n",
    "            for i in sell_index:\n",
    "                qty = int(self.stock_owned[i])\n",
    "                if qty > 0:\n",
    "                    symbol = self.symbols[i]\n",
    "                    sell(symbol, qty)\n",
    "                    self.stock_owned[i] = 0\n",
    "\n",
    "        if buy_index:\n",
    "            can_buy = True\n",
    "            while can_buy:\n",
    "                for i in buy_index:\n",
    "                    symbol = self.symbols[i]\n",
    "                    qty = 1\n",
    "                    if self.cash_in_hand > self.stock_price[i] and qty > 0:\n",
    "                        print(\"self.cash_in_hand: \", self.cash_in_hand, \"self.stock_price[i]: \", self.stock_price[i])\n",
    "                        buy(symbol, qty)\n",
    "                        self.stock_owned[i] += qty\n",
    "                        self.cash_in_hand -= self.stock_price[i]\n",
    "                    else:\n",
    "                        can_buy = False\n",
    "\n",
    "\n",
    "    def _get_stock_prices(self):\n",
    "        prices = []\n",
    "        for symbol in self.symbols:\n",
    "            market_price = get_latest_price(symbol)\n",
    "            prices.append(market_price)\n",
    "        return np.array(prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQNAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent(object):\n",
    "  def __init__(self, state_size, action_size):\n",
    "    self.state_size = state_size\n",
    "    self.action_size = action_size\n",
    "    self.memory = ReplayBuffer(state_size, action_size, size=500)\n",
    "    self.gamma = 0.95  # discount rate\n",
    "    self.epsilon = 1.0  # exploration rate\n",
    "    self.epsilon_min = 0.01\n",
    "    self.epsilon_decay = 0.995\n",
    "    self.model = mlp(state_size, action_size)\n",
    "\n",
    "\n",
    "  def update_replay_memory(self, state, action, reward, next_state, done):\n",
    "    self.memory.store(state, action, reward, next_state, done)\n",
    "\n",
    "\n",
    "  def act(self, state):\n",
    "    if np.random.rand() <= self.epsilon:\n",
    "      return np.random.choice(self.action_size)\n",
    "    act_values = self.model.predict(state)\n",
    "    return np.argmax(act_values[0])  # returns action\n",
    "\n",
    "\n",
    "  def replay(self, batch_size=32):\n",
    "    # first check if replay buffer contains enough data\n",
    "    if self.memory.size < batch_size:\n",
    "      return\n",
    "\n",
    "    # sample a batch of data from the replay memory\n",
    "    minibatch = self.memory.sample_batch(batch_size)\n",
    "    states = minibatch['s']\n",
    "    actions = minibatch['a']\n",
    "    rewards = minibatch['r']\n",
    "    next_states = minibatch['s2']\n",
    "    done = minibatch['d']\n",
    "\n",
    "    # Calculate the tentative target: Q(s',a)\n",
    "    target = rewards + (1 - done) * self.gamma * np.amax(self.model.predict(next_states), axis=1)\n",
    "\n",
    "    # With the Keras API, the target (usually) must have the same\n",
    "    # shape as the predictions.\n",
    "    # However, we only need to update the network for the actions\n",
    "    # which were actually taken.\n",
    "    # We can accomplish this by setting the target to be equal to\n",
    "    # the prediction for all values.\n",
    "    # Then, only change the targets for the actions taken.\n",
    "    # Q(s,a)\n",
    "    target_full = self.model.predict(states)\n",
    "    target_full[np.arange(batch_size), actions] = target\n",
    "\n",
    "    # Run one training step\n",
    "    self.model.train_on_batch(states, target_full)\n",
    "\n",
    "    if self.epsilon > self.epsilon_min:\n",
    "      self.epsilon *= self.epsilon_decay\n",
    "\n",
    "\n",
    "  def load(self, name):\n",
    "    self.model.load_weights(name)\n",
    "\n",
    "\n",
    "  def save(self, name):\n",
    "    self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 7)]               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 32)                256       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 27)                891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,147\n",
      "Trainable params: 1,147\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nguye\\anaconda3\\envs\\env_dlearning\\lib\\site-packages\\sklearn\\base.py:299: UserWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.cash_in_hand:  24299.627892130557 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  24198.017891520205 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  24096.407890909853 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  23994.797890299502 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  23893.18788968915 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  23791.5778890788 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  23689.967888468447 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  23588.357887858096 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  23486.747887247744 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  23385.137886637393 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  23283.52788602704 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  23181.91788541669 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  23080.307884806338 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  22978.697884195986 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  22877.087883585635 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  22775.477882975283 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  22673.86788236493 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  22572.25788175458 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  22470.64788114423 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  22369.037880533877 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  22267.427879923525 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  22165.817879313174 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  22064.207878702822 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  21962.59787809247 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  21860.98787748212 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  21759.377876871768 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  21657.767876261416 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  21556.157875651064 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  21454.547875040713 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  21352.93787443036 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  21251.32787382001 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  21149.717873209658 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  21048.107872599307 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  20946.497871988955 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  20844.887871378603 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  20743.277870768252 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  20641.6678701579 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  20540.05786954755 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  20438.447868937197 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  20336.837868326846 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  20235.227867716494 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  20133.617867106143 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  20032.00786649579 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  19930.39786588544 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  19828.787865275088 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  19727.177864664736 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  19625.567864054385 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  19523.957863444033 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  19422.34786283368 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  19320.73786222333 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  19219.12786161298 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  19117.517861002627 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  19015.907860392275 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  18914.297859781924 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  18812.687859171572 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  18711.07785856122 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  18609.46785795087 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  18507.857857340518 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  18406.247856730166 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  18304.637856119814 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  18203.027855509463 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  18101.41785489911 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  17999.80785428876 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  17898.197853678408 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  17796.587853068057 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  17694.977852457705 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  17593.367851847353 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  17491.757851237002 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  17390.14785062665 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  17288.5378500163 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  17186.927849405947 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  17085.317848795596 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  16983.707848185244 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  16882.097847574893 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  16780.48784696454 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  16678.87784635419 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  16577.267845743838 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  16475.657845133486 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  16374.047844523135 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  16272.437843912783 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  16170.827843302432 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  16069.21784269208 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  15967.607842081728 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  15865.997841471377 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  15764.387840861025 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  15662.777840250674 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  15561.167839640322 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  15459.55783902997 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  15357.947838419619 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  15256.337837809268 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  15154.727837198916 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  15053.117836588564 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  14951.507835978213 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  14849.897835367861 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  14748.28783475751 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  14646.677834147158 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  14545.067833536807 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  14443.457832926455 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  14341.847832316103 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  14240.237831705752 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  14138.6278310954 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  14037.017830485049 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  13935.407829874697 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  13833.797829264346 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  13732.187828653994 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  13630.577828043643 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  13528.967827433291 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  13427.35782682294 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  13325.747826212588 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  13224.137825602236 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  13122.527824991885 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  13020.917824381533 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  12919.307823771182 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  12817.69782316083 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  12716.087822550478 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  12614.477821940127 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  12512.867821329775 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  12411.257820719424 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  12309.647820109072 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  12208.03781949872 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  12106.427818888369 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  12004.817818278018 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  11903.207817667666 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  11801.597817057314 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  11699.987816446963 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  11598.377815836611 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  11496.76781522626 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  11395.157814615908 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  11293.547814005557 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  11191.937813395205 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  11090.327812784853 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  10988.717812174502 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  10887.10781156415 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  10785.497810953799 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  10683.887810343447 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  10582.277809733096 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  10480.667809122744 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  10379.057808512393 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  10277.447807902041 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  10175.83780729169 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  10074.227806681338 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  9972.617806070986 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  9871.007805460635 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  9769.397804850283 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  9667.787804239932 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  9566.17780362958 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  9464.567803019228 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  9362.957802408877 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  9261.347801798525 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  9159.737801188174 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  9058.127800577822 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  8956.51779996747 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  8854.907799357119 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  8753.297798746768 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  8651.687798136416 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  8550.077797526064 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  8448.467796915713 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  8346.857796305361 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  8245.24779569501 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  8143.637795084658 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  8042.027794474307 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  7940.417793863955 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  7838.807793253603 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  7737.197792643252 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  7635.5877920329 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  7533.977791422549 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  7432.367790812197 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  7330.757790201846 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  7229.147789591494 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  7127.5377889811425 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  7025.927788370791 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  6924.317787760439 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  6822.707787150088 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  6721.097786539736 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  6619.487785929385 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  6517.877785319033 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  6416.267784708682 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  6314.65778409833 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  6213.047783487978 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  6111.437782877627 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  6009.827782267275 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  5908.217781656924 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  5806.607781046572 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  5704.997780436221 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  5603.387779825869 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  5501.7777792155175 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  5400.167778605166 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  5298.557777994814 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  5196.947777384463 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  5095.337776774111 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  4993.72777616376 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  4892.117775553408 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  4790.507774943057 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  4688.897774332705 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  4587.287773722353 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  4485.677773112002 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  4384.06777250165 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  4282.457771891299 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  4180.847771280947 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  4079.2377706705956 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  3977.627770060244 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  3876.0177694498925 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  3774.407768839541 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  3672.7977682291894 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  3571.187767618838 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  3469.5777670084863 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  3367.9677663981347 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  3266.357765787783 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  3164.7477651774316 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  3063.13776456708 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  2961.5277639567284 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  2859.917763346377 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  2758.3077627360253 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  2656.6977621256738 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  2555.087761515322 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  2453.4777609049706 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  2351.867760294619 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  2250.2577596842675 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  2148.647759073916 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  2047.0377584635644 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  1945.4277578532128 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  1843.8177572428613 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  1742.2077566325097 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  1640.5977560221581 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  1538.9877554118066 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  1437.377754801455 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  1335.7677541911034 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  1234.157753580752 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  1132.5477529704003 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  1030.9377523600488 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  929.3277517496972 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  827.7177511393456 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  726.1077505289941 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  624.4977499186425 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  522.887749308291 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  421.2777486979394 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  319.6677480875878 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  218.05774747723626 self.stock_price[i]:  101.61000061035156\n",
      "self.cash_in_hand:  116.4477468668847 self.stock_price[i]:  101.61000061035156\n"
     ]
    },
    {
     "ename": "APIError",
     "evalue": "insufficient buying power",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\env_dlearning\\lib\\site-packages\\alpaca_trade_api\\rest.py:234\u001b[0m, in \u001b[0;36mREST._one_request\u001b[1;34m(self, method, url, opts, retry)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 234\u001b[0m     resp\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[0;32m    235\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m http_error:\n\u001b[0;32m    236\u001b[0m     \u001b[39m# retry if we hit Rate Limit\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://paper-api.alpaca.markets/v2/orders",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\machine_learning_examples\\tf2.0\\test_trader_alpaca.ipynb Cell 21\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/machine_learning_examples/tf2.0/test_trader_alpaca.ipynb#X26sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# remake the env with test data \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/machine_learning_examples/tf2.0/test_trader_alpaca.ipynb#X26sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m env \u001b[39m=\u001b[39m EvnAlpaca(symbols, initial_investment)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/machine_learning_examples/tf2.0/test_trader_alpaca.ipynb#X26sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m scaler \u001b[39m=\u001b[39m get_scaler(env)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/machine_learning_examples/tf2.0/test_trader_alpaca.ipynb#X26sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# make sure epsilon is not 1!\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/machine_learning_examples/tf2.0/test_trader_alpaca.ipynb#X26sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# no need to run multiple episodes if epsilon = 0, it's deterministic\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/machine_learning_examples/tf2.0/test_trader_alpaca.ipynb#X26sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m agent\u001b[39m.\u001b[39mepsilon \u001b[39m=\u001b[39m \u001b[39m0.01\u001b[39m\n",
      "\u001b[1;32md:\\machine_learning_examples\\tf2.0\\test_trader_alpaca.ipynb Cell 21\u001b[0m in \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/machine_learning_examples/tf2.0/test_trader_alpaca.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(env\u001b[39m.\u001b[39mn_step):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/machine_learning_examples/tf2.0/test_trader_alpaca.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   action \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(env\u001b[39m.\u001b[39maction_space)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/machine_learning_examples/tf2.0/test_trader_alpaca.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   state, reward, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/machine_learning_examples/tf2.0/test_trader_alpaca.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m   states\u001b[39m.\u001b[39mappend(state)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/machine_learning_examples/tf2.0/test_trader_alpaca.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m   \u001b[39mif\u001b[39;00m done:\n",
      "\u001b[1;32md:\\machine_learning_examples\\tf2.0\\test_trader_alpaca.ipynb Cell 21\u001b[0m in \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/machine_learning_examples/tf2.0/test_trader_alpaca.ipynb#X26sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstock_price \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_stock_prices()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/machine_learning_examples/tf2.0/test_trader_alpaca.ipynb#X26sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39m# perform the trade\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/machine_learning_examples/tf2.0/test_trader_alpaca.ipynb#X26sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_trade(action)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/machine_learning_examples/tf2.0/test_trader_alpaca.ipynb#X26sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39m# get the new value after taking the action\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/machine_learning_examples/tf2.0/test_trader_alpaca.ipynb#X26sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m cur_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_val()\n",
      "\u001b[1;32md:\\machine_learning_examples\\tf2.0\\test_trader_alpaca.ipynb Cell 21\u001b[0m in \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/machine_learning_examples/tf2.0/test_trader_alpaca.ipynb#X26sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m         \u001b[39mif\u001b[39;00m qty \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/machine_learning_examples/tf2.0/test_trader_alpaca.ipynb#X26sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m             symbol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msymbols[i]\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/machine_learning_examples/tf2.0/test_trader_alpaca.ipynb#X26sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m             sell(symbol, qty)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/machine_learning_examples/tf2.0/test_trader_alpaca.ipynb#X26sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstock_owned[i] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/machine_learning_examples/tf2.0/test_trader_alpaca.ipynb#X26sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m \u001b[39mif\u001b[39;00m buy_index:\n",
      "\u001b[1;32md:\\machine_learning_examples\\tf2.0\\test_trader_alpaca.ipynb Cell 21\u001b[0m in \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/machine_learning_examples/tf2.0/test_trader_alpaca.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msell\u001b[39m(symbol, qty):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/machine_learning_examples/tf2.0/test_trader_alpaca.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     api\u001b[39m.\u001b[39;49msubmit_order(symbol\u001b[39m=\u001b[39;49msymbol, qty\u001b[39m=\u001b[39;49mqty,side\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msell\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mtype\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmarket\u001b[39;49m\u001b[39m'\u001b[39;49m, time_in_force\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgtc\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\env_dlearning\\lib\\site-packages\\alpaca_trade_api\\rest.py:429\u001b[0m, in \u001b[0;36mREST.submit_order\u001b[1;34m(self, symbol, qty, side, type, time_in_force, limit_price, stop_price, client_order_id, extended_hours, order_class, take_profit, stop_loss, trail_price, trail_percent, notional)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[39mif\u001b[39;00m trail_percent \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    428\u001b[0m     params[\u001b[39m'\u001b[39m\u001b[39mtrail_percent\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m trail_percent\n\u001b[1;32m--> 429\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpost(\u001b[39m'\u001b[39;49m\u001b[39m/orders\u001b[39;49m\u001b[39m'\u001b[39;49m, params)\n\u001b[0;32m    430\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresponse_wrapper(resp, Order)\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\env_dlearning\\lib\\site-packages\\alpaca_trade_api\\rest.py:253\u001b[0m, in \u001b[0;36mREST.post\u001b[1;34m(self, path, data)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\u001b[39mself\u001b[39m, path, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 253\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\u001b[39m'\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m'\u001b[39;49m, path, data)\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\env_dlearning\\lib\\site-packages\\alpaca_trade_api\\rest.py:213\u001b[0m, in \u001b[0;36mREST._request\u001b[1;34m(self, method, path, data, base_url, api_version)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[39mwhile\u001b[39;00m retry \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    212\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 213\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_one_request(method, url, opts, retry)\n\u001b[0;32m    214\u001b[0m     \u001b[39mexcept\u001b[39;00m RetryException:\n\u001b[0;32m    215\u001b[0m         retry_wait \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retry_wait\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\env_dlearning\\lib\\site-packages\\alpaca_trade_api\\rest.py:242\u001b[0m, in \u001b[0;36mREST._one_request\u001b[1;34m(self, method, url, opts, retry)\u001b[0m\n\u001b[0;32m    240\u001b[0m     error \u001b[39m=\u001b[39m resp\u001b[39m.\u001b[39mjson()\n\u001b[0;32m    241\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m error:\n\u001b[1;32m--> 242\u001b[0m         \u001b[39mraise\u001b[39;00m APIError(error, http_error)\n\u001b[0;32m    243\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mAPIError\u001b[0m: insufficient buying power"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "  # config\n",
    "  models_folder = 'rl_trader_models'\n",
    "  rewards_folder = 'rl_trader_rewards'\n",
    "  num_episodes = 25\n",
    "  batch_size = 32\n",
    "  symbols = ['AAPL', 'MSI', 'SBUX']\n",
    "  initial_investment = get_balance()\n",
    "\n",
    "  args = \"test\"\n",
    "\n",
    "  maybe_make_dir(models_folder)\n",
    "  maybe_make_dir(rewards_folder)\n",
    "\n",
    "  data = get_data()\n",
    "  n_timesteps, n_stocks = data.shape\n",
    "\n",
    "  n_train = n_timesteps // 2\n",
    "\n",
    "  train_data = data[:n_train]\n",
    "  test_data = data[n_train:]\n",
    "  env = EvnAlpaca(symbols, initial_investment)\n",
    "  state_size = env.state_dim\n",
    "  action_size = len(env.action_space)\n",
    "  agent = DQNAgent(state_size, action_size)\n",
    "  \n",
    "\n",
    "  # store the final value of the portfolio (end of episode)\n",
    "  portfolio_value = []\n",
    "\n",
    "  if args == 'test':\n",
    "    # then load the previous scaler\n",
    "    with open(f'{models_folder}/scaler.pkl', 'rb') as f:\n",
    "      scaler = pickle.load(f)\n",
    "\n",
    "    # remake the env with test data \n",
    "    env = EvnAlpaca(symbols, initial_investment)\n",
    "    scaler = get_scaler(env)\n",
    "\n",
    "    # make sure epsilon is not 1!\n",
    "    # no need to run multiple episodes if epsilon = 0, it's deterministic\n",
    "    agent.epsilon = 0.01\n",
    "\n",
    "    # load trained weights\n",
    "    agent.load(f'{models_folder}/dqn.h5')\n",
    "\n",
    "  # play the game num_episodes times\n",
    "  for e in range(num_episodes):\n",
    "    t0 = datetime.now()\n",
    "    val = play_one_episode(agent, env, args)\n",
    "    dt = datetime.now() - t0\n",
    "    print(f\"episode: {e + 1}/{num_episodes}, episode end value: {val:.2f}, duration: {dt}\")\n",
    "    portfolio_value.append(val) # append episode end portfolio value\n",
    "\n",
    "  # save portfolio value for each episode\n",
    "  np.save(f'{rewards_folder}/{args}.npy', portfolio_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dlearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
